{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EYE_AR_THRESH = 0.3\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "YAWN_THRESH = 0.5  \n",
    "HEAD_MOVEMENT_THRESH = 20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_yawn(shape):\n",
    "    mouth = shape[48:68]\n",
    "    A = distance.euclidean(mouth[3], mouth[9])\n",
    "    B = distance.euclidean(mouth[2], mouth[10])\n",
    "    C = distance.euclidean(mouth[4], mouth[8])\n",
    "    D = distance.euclidean(mouth[0], mouth[6])\n",
    "    ratio = (A + B + C) / (3.0 * D)\n",
    "    return ratio > YAWN_THRESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_head_movement(shape, prev_shape):\n",
    "    if prev_shape is None:\n",
    "        return 0\n",
    "    current_head_pos = np.mean(shape[30:36], axis=0) \n",
    "    prev_head_pos = np.mean(prev_shape[30:36], axis=0)\n",
    "    movement = np.linalg.norm(current_head_pos - prev_head_pos)\n",
    "    return movement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, duration=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Unable to open video file at {video_path}\")\n",
    "        return {}\n",
    "    \n",
    "    blink_count = 0\n",
    "    consecutive_closed_frames = 0\n",
    "    open_eyes_durations = []\n",
    "    closed_eyes_durations = []\n",
    "    yawning_count = 0\n",
    "    head_movement_count = 0\n",
    "    prev_shape = None\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(duration * fps)\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened() and frame_count < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Warning: End of video or error reading frame\")\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "\n",
    "        for rect in rects:\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "            leftEye = shape[face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"][0]:face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"][1]]\n",
    "            rightEye = shape[face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"][0]:face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"][1]]\n",
    "\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                consecutive_closed_frames += 1\n",
    "            else:\n",
    "                if consecutive_closed_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "                    closed_eyes_durations.append(consecutive_closed_frames)\n",
    "                consecutive_closed_frames = 0\n",
    "                open_eyes_durations.append(frame_count)\n",
    "\n",
    "            if detect_yawn(shape):\n",
    "                yawning_count += 1\n",
    "\n",
    "            head_movement = detect_head_movement(shape, prev_shape)\n",
    "            if head_movement > HEAD_MOVEMENT_THRESH:\n",
    "                head_movement_count += 1\n",
    "\n",
    "            prev_shape = shape\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    open_eye_avg_duration = np.mean(open_eyes_durations) if open_eyes_durations else 0\n",
    "    closed_eye_avg_duration = np.mean(closed_eyes_durations) if closed_eyes_durations else 0\n",
    "    eye_closure_ratio = sum(closed_eyes_durations) / frame_count if frame_count > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'blink_count': blink_count,\n",
    "        'closed_eye_avg_duration': closed_eye_avg_duration,\n",
    "        'open_eye_avg_duration': open_eye_avg_duration,\n",
    "        'eye_closure_ratio': eye_closure_ratio,\n",
    "        'yawning_count': yawning_count,\n",
    "        'head_movement_count': head_movement_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos_in_folder(folder_path, label, duration=10):\n",
    "    results = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(folder_path, filename)\n",
    "            features = process_video(video_path, duration)\n",
    "            features['label'] = label\n",
    "            features['filename'] = filename\n",
    "            results.append(features)\n",
    "    return results\n",
    "\n",
    "drowsiness_folder = 'C:/Users/Neomi/Desktop/DL project/project/drowsiness-level/data/drowsiness'\n",
    "not_drowsiness_folder = 'C:/Users/Neomi/Desktop/DL project/project/drowsiness-level/data/not drowsiness'\n",
    "\n",
    "drowsiness_results = process_videos_in_folder(drowsiness_folder, label=1)\n",
    "not_drowsiness_results = process_videos_in_folder(not_drowsiness_folder, label=0)\n",
    "\n",
    "results_df = pd.DataFrame(drowsiness_results + not_drowsiness_results)\n",
    "\n",
    "results_df.to_csv('C:/Users/Neomi/Desktop/DL project/project/drowsiness-level/data/driver_fatigue_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(drowsiness_results + not_drowsiness_results)\n",
    "results_df.to_csv('C:/Users/Neomi/Desktop/DL project/project/drowsiness-level/data/driver_fatigue_features_results.csv', index=False)\n",
    "drowsiness_results_df = pd.DataFrame(drowsiness_results)\n",
    "not_drowsiness_results_df = pd.DataFrame(not_drowsiness_results)\n",
    "drowsiness_results_df.to_csv('C:/Users/Neomi/Desktop/DL project/project/drowsiness-level/data/driver_fatigue_features_drowsiness_results.csv', index=False)\n",
    "not_drowsiness_results_df.to_csv('C:/Users/Neomi/Desktop/DL project/project/drowsiness-level/data/driver_fatigue_features_not_drowsiness_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6265060240963856\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.66       219\n",
      "           1       0.62      0.56      0.58       196\n",
      "\n",
      "    accuracy                           0.63       415\n",
      "   macro avg       0.63      0.62      0.62       415\n",
      "weighted avg       0.63      0.63      0.62       415\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  68]\n",
      " [ 87 109]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Neomi/Desktop/DL project/project/drowsiness-level/data/driver_fatigue_features_results.csv')\n",
    "numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "numeric_data['label'] = data['label']\n",
    "\n",
    "X = numeric_data.drop('label', axis=1) \n",
    "y = numeric_data['label'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.6313253012048192\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       219\n",
      "           1       0.62      0.57      0.59       196\n",
      "\n",
      "    accuracy                           0.63       415\n",
      "   macro avg       0.63      0.63      0.63       415\n",
      "weighted avg       0.63      0.63      0.63       415\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  69]\n",
      " [ 84 112]]\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6409638554216868\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68       219\n",
      "           1       0.64      0.54      0.59       196\n",
      "\n",
      "    accuracy                           0.64       415\n",
      "   macro avg       0.64      0.64      0.63       415\n",
      "weighted avg       0.64      0.64      0.64       415\n",
      "\n",
      "Confusion Matrix:\n",
      " [[160  59]\n",
      " [ 90 106]]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
