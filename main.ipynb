{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "from imutils import face_utils\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pre-trained face detector and landmark predictor from dlib\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Constants for blink detection\n",
    "EYE_AR_THRESH = 0.3\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "\n",
    "# detector = dlib.get_frontal_face_detector()\n",
    "# predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# print(\"Dlib modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # Compute the euclidean distances between the two sets of vertical eye landmarks (x, y)-coordinates\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "\n",
    "    # Compute the euclidean distance between the horizontal eye landmark (x, y)-coordinates\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "\n",
    "    # Compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, duration=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    blink_count = 0\n",
    "    total_eye_closure_duration = 0\n",
    "    frame_count = 0\n",
    "    open_eyes_durations = []\n",
    "    closed_eyes_durations = []\n",
    "    consecutive_closed_frames = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "\n",
    "        for rect in rects:\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "            leftEye = shape[face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"][0]:face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"][1]]\n",
    "            rightEye = shape[face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"][0]:face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"][1]]\n",
    "            \n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                consecutive_closed_frames += 1\n",
    "            else:\n",
    "                if consecutive_closed_frames >= EYE_AR_CONSEC_FRAMES:\n",
    "                    blink_count += 1\n",
    "                    closed_eyes_durations.append(consecutive_closed_frames)\n",
    "                consecutive_closed_frames = 0\n",
    "                open_eyes_durations.append(frame_count)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count >= duration * cap.get(cv2.CAP_PROP_FPS):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    open_eye_avg_duration = np.mean(open_eyes_durations) if open_eyes_durations else 0\n",
    "    closed_eye_avg_duration = np.mean(closed_eyes_durations) if closed_eyes_durations else 0\n",
    "    eye_closure_ratio = sum(closed_eyes_durations) / frame_count if frame_count > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'blink_count': blink_count,\n",
    "        'closed_eye_avg_duration': closed_eye_avg_duration,\n",
    "        'open_eye_avg_duration': open_eye_avg_duration,\n",
    "        'eye_closure_ratio': eye_closure_ratio\n",
    "    }\n",
    "\n",
    "def process_videos_in_folder(folder_path, label, duration=30):\n",
    "    results = []\n",
    "    i = 0\n",
    "    for filename in os.listdir(folder_path):\t\n",
    "        if filename.endswith(\".mp4\") and i < 10:\n",
    "            video_path = os.path.join(folder_path, filename)\n",
    "            i = i+1\n",
    "            # print(video_path)\n",
    "            features = process_video(video_path, duration)\n",
    "            features['label'] = label\n",
    "            results.append(features)\n",
    "    return results\n",
    "\n",
    "# Process videos in 'data/drowsiness' folder\n",
    "drowsiness_folder = 'data/drowsiness'\n",
    "drowsiness_results = process_videos_in_folder(drowsiness_folder, label=1)\n",
    "\n",
    "# Process videos in 'data/not_drowsiness' folder\n",
    "not_drowsiness_folder = 'data/not drowsiness'\n",
    "not_drowsiness_results = process_videos_in_folder(not_drowsiness_folder, label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'blink_count': 2,\n",
       "  'closed_eye_avg_duration': np.float64(93.0),\n",
       "  'open_eye_avg_duration': np.float64(136.24137931034483),\n",
       "  'eye_closure_ratio': 0.62,\n",
       "  'label': 1},\n",
       " {'blink_count': 3,\n",
       "  'closed_eye_avg_duration': np.float64(32.0),\n",
       "  'open_eye_avg_duration': np.float64(113.4),\n",
       "  'eye_closure_ratio': 0.32,\n",
       "  'label': 1},\n",
       " {'blink_count': 3,\n",
       "  'closed_eye_avg_duration': np.float64(9.0),\n",
       "  'open_eye_avg_duration': np.float64(126.91928251121077),\n",
       "  'eye_closure_ratio': 0.108,\n",
       "  'label': 1},\n",
       " {'blink_count': 3,\n",
       "  'closed_eye_avg_duration': np.float64(5.666666666666667),\n",
       "  'open_eye_avg_duration': np.float64(120.13304721030043),\n",
       "  'eye_closure_ratio': 0.068,\n",
       "  'label': 1},\n",
       " {'blink_count': 2,\n",
       "  'closed_eye_avg_duration': np.float64(7.5),\n",
       "  'open_eye_avg_duration': np.float64(121.7008547008547),\n",
       "  'eye_closure_ratio': 0.06,\n",
       "  'label': 1},\n",
       " {'blink_count': 2,\n",
       "  'closed_eye_avg_duration': np.float64(12.0),\n",
       "  'open_eye_avg_duration': np.float64(122.39823008849558),\n",
       "  'eye_closure_ratio': 0.096,\n",
       "  'label': 1},\n",
       " {'blink_count': 2,\n",
       "  'closed_eye_avg_duration': np.float64(8.0),\n",
       "  'open_eye_avg_duration': np.float64(125.93913043478261),\n",
       "  'eye_closure_ratio': 0.064,\n",
       "  'label': 1},\n",
       " {'blink_count': 6,\n",
       "  'closed_eye_avg_duration': np.float64(9.666666666666666),\n",
       "  'open_eye_avg_duration': np.float64(107.1731843575419),\n",
       "  'eye_closure_ratio': 0.232,\n",
       "  'label': 1},\n",
       " {'blink_count': 4,\n",
       "  'closed_eye_avg_duration': np.float64(8.75),\n",
       "  'open_eye_avg_duration': np.float64(115.57674418604651),\n",
       "  'eye_closure_ratio': 0.14,\n",
       "  'label': 1},\n",
       " {'blink_count': 6,\n",
       "  'closed_eye_avg_duration': np.float64(8.0),\n",
       "  'open_eye_avg_duration': np.float64(114.73869346733669),\n",
       "  'eye_closure_ratio': 0.192,\n",
       "  'label': 1}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drowsiness_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
